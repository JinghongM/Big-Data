sqoop list-databases \
--connect jdbc:mysql://localhost \
--username root \
--password hadoop


sqoop list-tables \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop

sqoop eval --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--query "SELECT * FROM orders LIMIT 10"

sqoop eval --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--query \
"INSERT INTO orders VALUES (100000,"2017-10-31 00:00:00.0" 100000 'DUMMY')"

sqoop import --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--table products
--warehouse-dir /user/maria_dev/cca-175/sqoop/
(-- num-mappers 1)
(--append)
(IF not working, add: --driver com.mysql.jdbc.Driver)

sqoop import --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--table order_items \
--warehouse-dir /user/maria_dev/sqoop/order_items \
--delete-target-dir(If there is a reundent file 
which has the same as destination file)

//Thing to remember for split-by
//Column should be indexed
//values in the field should be sparse
//also should be sequence generated
//it should not have null values

sqoop import --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--table order_copy
--warehouse-dir /user/maria_dev/cca-175/sqoop/
--split-by order_id

sqoop import --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--table order_items \
--warehouse-dir /user/maria_dev/cca-175/sqoop \
--num-mappers 2 \
--as-sequencefile

sqoop import --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--table order_items \
--warehouse-dir /user/maria_dev/cca-175/sqoop \
--num-mappers 2 \
--as-textfile \
--compress

sqoop import --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--table order_items \
--warehouse-dir /user/maria_dev/cca-175/sqoop/ \
--boundary-query \
'select min(order_item_id),max(order_item_id) from order_items where order_item_id >=99999'

sqoop import --connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--table order_items \
--columns order_item_order_id,order_item_id,order_item_subtotal \
--warehouse-dir /user/maria_dev/cca-175/sqoop/ 

sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--target-dir /user/maria_dev/cca-175/sqoop/orders \
--num-mappers 2 \
--query "select * from orders where \$CONDITIONS and order_date like '2014-01%'" \
--split-by order_id \
--append

sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--driver com.mysql.jdbc.Driver \
--target-dir /user/maria_dev/cca-175/sqoop/orders \
--num-mappers 2 \
--table orders \
--where "order_date like '2014-02%'" \
--append

sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--driver com.mysql.jdbc.Driver \
--target-dir /user/maria_dev/cca-175/sqoop/orders \
--num-mappers 2 \
--table orders \
--check-column order_date \
--incremental append \
--last-value '2014-02-28' \
--append

------------------------------------------------------------------------------

sqoop - hive

sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--driver com.mysql.jdbc.Driver \
--table order_items \
--hive-import \
--hive-database sqoop_import \
--hive-table order_items \
--num-mappers 2

sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--driver com.mysql.jdbc.Driver \
--table order_items \
--hive-import \
--hive-database sqoop_import \
--hive-table order_items \
--hive-overwrite \
--num-mappers 2

sqoop import-all-tables \
--connect jdbc:mysql://localhost/retail_db \
--username root \
--password hadoop \
--driver com.mysql.jdbc.Driver \
--warehouse-dir /user/maria_dev/cca-175/sqoop_hive \
--autoreset-to-one-mapper

create table daily_revenue as
select order_date,sum(order_item_subtotal) daily_revenue
from orders join order_items on
order_id = order_item_order_id
where order_date like '2013-07%'
group by order_date limit 10;
------------------------------------------------
export to RDBMS


sqoop export \
--connect jdbc:mysql://localhost/retail_export \
--username root \
--password hadoop \
--export-dir /apps/hive/warehouse/sqoop_import.db/daily_revenue \
--table daily_revenue \
--input-fields-terminated-by "\001" \
--num-mappers 1

create table daily_revenue_demo
(
	revenue float,
	order_date varchar(30),
	description varchar(200) not null
);

sqoop export \
--connect jdbc:mysql://localhost/retail_export \
--username root \
--password hadoop \
--export-dir /apps/hive/warehouse/sqoop_import.db/daily_revenue \
--table daily_revenue \
--columns order_date,revenue \
--input-fields-terminated-by "\001" \
--num-mappers 1

create table daily_revenue(
	order_date varchar(30) primary key,
	revenue float
);

sqoop export \
--connect jdbc:mysql://localhost/retail_export \
--username root \
--password hadoop \
--export-dir /apps/hive/warehouse/sqoop_import.db/daily_revenue \
--table daily_revenue \
--update-key order_date \
--input-fields-terminated-by "\001" \
--num-mappers 1

sqoop export \
--connect jdbc:mysql://localhost/retail_export \
--username root \
--password hadoop \
--export-dir /apps/hive/warehouse/sqoop_import.db/daily_revenue \
--table daily_revenue \
--update-key order_date \
--update-mode allowinsert \
--input-fields-terminated-by "\001" \
--num-mappers 1

insert into table daily_revenue
select order_date,sum(order_item_subtotal) daily_revenue
from orders join order_items on
order_id = order_item_order_id
where order_date like '2013-08%'
group by order_date;

insert into table daily_revenue
select order_date,sum(order_item_subtotal) daily_revenue
from orders join order_items on
order_id = order_item_order_id
group by order_date;

create table daily_revenue_stage(
	order_date varchar(30) primary key,
	revenue float
);

sqoop export \
--connect jdbc:mysql://localhost/retail_export \
--username root \
--password hadoop \
--export-dir /apps/hive/warehouse/sqoop_import.db/daily_revenue \
--table daily_revenue \
--staging-table daily_revenue_stage \
--clear-staging-table \
--input-fields-terminated-by "\001" \
--num-mappers 1

Hive table: daily_revenue -> mysql table:daily_revenue_stage - > daily_revenue
